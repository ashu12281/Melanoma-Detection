{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRHXvUS2c151PodC21mIGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashu12281/Melanoma-Detection/blob/main/MelanomaDetectionWithAugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Data Reading/Data Understanding → Defining the path for train and test images **"
      ],
      "metadata": {
        "id": "G9RPWQB_WoiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mount google drive"
      ],
      "metadata": {
        "id": "5_j7IkcCZuY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "4cQa4WW0ZyDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary libraries"
      ],
      "metadata": {
        "id": "c3RjB5pJbCzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "metadata": {
        "id": "SR_0Xp6KbJND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining path for test and train datasets"
      ],
      "metadata": {
        "id": "H_jhvZM4bVKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_train = pathlib.Path(\"/content/drive/MyDrive/CNN_assignment/Skin_cancer_ISIC_The_International_Skin_Imaging_Collaboration/Train/\")\n",
        "\n",
        "data_dir_test = pathlib.Path('/content/drive/MyDrive/CNN_assignment/Skin_cancer_ISIC_The_International_Skin_Imaging_Collaboration/Test/')\n"
      ],
      "metadata": {
        "id": "sKQzhdETaLTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets find out how many samples we have for each category."
      ],
      "metadata": {
        "id": "-rVebEI8bqv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Image count\n",
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "\n",
        "#Test Image count\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)\n"
      ],
      "metadata": {
        "id": "kZ6Q1cgIbsG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 : Dataset Creation→ Create train & validation dataset from the train directory with a batch size of 32. Also, make sure you resize your images to 180*180.**"
      ],
      "metadata": {
        "id": "yQMjbqHEmIOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining parameters for loaders\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "jZc_IoP9mONg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using 80% for training and 20% for testing/validation"
      ],
      "metadata": {
        "id": "gFqA_wRJm5A7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train datset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,image_size=(180,180),label_mode='categorical',\n",
        "                                                              seed=123,subset=\"training\",validation_split=0.8)"
      ],
      "metadata": {
        "id": "hxpgMbZPm_IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validation Dataset\n",
        "val_ds =tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,image_size=(180,180),label_mode='categorical',\n",
        "                                                              seed=123,subset=\"validation\",validation_split=0.2)"
      ],
      "metadata": {
        "id": "g7e3VkaAn0Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing different classes of melanoma\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "64v3WMZuoRFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** **Step 3 : Dataset visualisation → Create a code to visualize one instance of all the nine classes present in the dataset** **"
      ],
      "metadata": {
        "id": "dU8hDSKIojS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "#Dictionary to store the path of image as per the class\n",
        "files_path_dict = {}\n",
        "\n",
        "for c in class_names:\n",
        "    files_path_dict[c] = list(map(lambda x:str(data_dir_train)+'/'+c+'/'+x,os.listdir(str(data_dir_train)+'/'+c)))\n",
        "\n",
        "#Visualize image\n",
        "fig=plt.figure(figsize=(20,10))\n",
        "fig.subplots_adjust(wspace=0.2, hspace=0.4)\n",
        "index = 0\n",
        "for c in class_names:\n",
        "    path_list = files_path_dict[c][:1]\n",
        "    index += 1\n",
        "    plt.subplot(3,3,index)\n",
        "    plt.imshow(load_img(path_list[0],target_size=(img_height,img_width)))\n",
        "    plt.title(c)"
      ],
      "metadata": {
        "id": "7fs3EAxCocXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image_batch is a tensor of the shape (32, 180, 180, 3). This is a batch of 32 images of shape 180x180x3 (the last dimension refers to color channels RGB). The label_batch is a tensor of the shape (32,), these are corresponding labels to the 32 images.\n",
        "\n",
        "Dataset.cache() keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "Dataset.prefetch() overlaps data preprocessing and model execution while training."
      ],
      "metadata": {
        "id": "Ji3GKrEjpw5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "lPZEVNmop5S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Model Building & training :\n",
        "Create a CNN model, which can accurately detect 9 classes present in the dataset. While building the model, rescale images to normalize pixel values between (0,1).\n",
        "Choose an appropriate optimiser and loss function for model training\n",
        "Train the model for ~20 epochs\n",
        "Write your findings after the model fit. You must check if there is any evidence of model overfit or underfit.**"
      ],
      "metadata": {
        "id": "iKRaa8glqNGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (img_height,img_width,3)\n",
        "\n",
        "model = Sequential()    #Sequential allows you to create models layer-by-layer\n",
        "\n",
        "#First Convulation Layer\n",
        "model.add(layers.experimental.preprocessing.Rescaling(1./255,input_shape=input_shape))\n",
        "model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Second Convulation Layer\n",
        "model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Third Convulation Layer\n",
        "model.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(layers.Flatten())   #Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.\n",
        "\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "\n",
        "#Dense Layer with softmax activation function.\n",
        "#Softmax is an activation function that scales numbers/logits into probabilities.\n",
        "model.add(layers.Dense(len(class_names),activation='softmax'))"
      ],
      "metadata": {
        "id": "syFx-XiWqUkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model"
      ],
      "metadata": {
        "id": "DpMU7NqfqlFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Adam optimization: is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
        "#categorical_crossentropy: Used as a loss function for multi-class classification model where there are two or more output labels.\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "D2afdGl4u2oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of all layers\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "B5Z00sG4u9gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "akh1Hy9NvHCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "AixyTQ8hvFpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing training result"
      ],
      "metadata": {
        "id": "2Ar6ekRBvPxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "noYbc-tpvS1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model is overfitting. From the above Training vs Validation accuracy graph we can see that as the epoch increases the difference between Training accuracy and validation accuracy increases."
      ],
      "metadata": {
        "id": "fpeTyH8RvYI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5 - Chose an appropriate data augmentation strategy to resolve underfitting/overfitting**"
      ],
      "metadata": {
        "id": "hx6AMNhFvfjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rescale = tf.keras.Sequential([\n",
        "  #To rescale an input in the [0, 255] range to be in the [0, 1] range\n",
        "  layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  #Randomly flip each image horizontally and vertically.\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "\n",
        "  #Randomly rotate each image.\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "\n",
        "  #Randomly zoom each image during training.\n",
        "  layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "\n",
        "  #Randomly translate each image during training.\n",
        "  layers.experimental.preprocessing.RandomTranslation(0.1, 0.1)\n",
        "])"
      ],
      "metadata": {
        "id": "KBH0j8XuvcaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the augmentation image\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Pi4IHTdhvuAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6 - Model Building & training on the augmented data :\n",
        "Create a CNN model, which can accurately detect 9 classes present in the dataset. While building the model rescale images to normalize pixel values between (0,1).\n",
        "Choose an appropriate optimiser and loss function for model training\n",
        "Train the model for ~20 epochs\n",
        "Write your findings after the model fit, see if the earlier issue is resolved or not?**"
      ],
      "metadata": {
        "id": "B3I5Mx3mv0xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropout layer: randomly sets input units to 0 with a frequency of rate at each step during training time,\n",
        "#which helps prevent overfitting.Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
        "\n",
        "\n",
        "## Your code goes here\n",
        "model2 = Sequential()                     #Sequential allows you to create models layer-by-layer\n",
        "\n",
        "model2.add(data_augmentation)             #Augmentation layer\n",
        "model2.add(rescale)                       #Rescaling layer\n",
        "\n",
        "#First Convulation Layer\n",
        "model2.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model2.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Dropout layer with 25% Fraction of the input units to drop.\n",
        "model2.add(layers.Dropout(0.25))\n",
        "\n",
        "#Second Convulation Layer\n",
        "model2.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model2.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Dropout layer with 25% Fraction of the input units to drop.\n",
        "model2.add(layers.Dropout(0.25))\n",
        "\n",
        "#Third Convulation Layer\n",
        "model2.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model2.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.\n",
        "model2.add(layers.Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "model2.add(layers.Dense(512,activation='relu'))\n",
        "\n",
        "#Dense Layer\n",
        "model2.add(layers.Dense(128,activation='relu'))\n",
        "\n",
        "#Dropout layer with 50% Fraction of the input units to drop.\n",
        "model2.add(layers.Dropout(0.50))\n",
        "\n",
        "#Dense Layer with softmax activation function.\n",
        "#Softmax is an activation function that scales numbers/logits into probabilities.\n",
        "model2.add(layers.Dense(len(class_names),activation='softmax'))"
      ],
      "metadata": {
        "id": "tjZxuJWCv6mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling th e model"
      ],
      "metadata": {
        "id": "abPFNxYxwBfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='Adam',\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rF2EJ0Y_wEWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model on augmented data"
      ],
      "metadata": {
        "id": "EMEcQX-0wJK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs =20\n",
        "history = model2.fit(train_ds,epochs=epochs,validation_data=val_ds,verbose=1)"
      ],
      "metadata": {
        "id": "FmvhhfJkwMSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualising the result"
      ],
      "metadata": {
        "id": "Kw2_tzW_wPqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xL95aHLJwR6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations -\n",
        "\n",
        "*   After using data augumentation and dropout layer overfitting issue is reduce.\n",
        "*   Model Performance is still not increased. Will check the distribution of classes in the training set to check is there have class imbalance."
      ],
      "metadata": {
        "id": "U7tdxr1iwWd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Detecting if there is any class imbalanecc\n",
        "def class_distribution_count(directory):\n",
        "\n",
        "    #count number of image in each classes\n",
        "    count= []\n",
        "    for path in pathlib.Path(directory).iterdir():\n",
        "        if path.is_dir():\n",
        "            count.append(len([name for name in os.listdir(path)\n",
        "                               if os.path.isfile(os.path.join(path, name))]))\n",
        "\n",
        "    #name of the classes\n",
        "    sub_directory = [name for name in os.listdir(directory)\n",
        "                    if os.path.isdir(os.path.join(directory, name))]\n",
        "\n",
        "    #return dataframe with image count and class.\n",
        "    return pd.DataFrame(list(zip(sub_directory,count)),columns =['Class', 'No. of Image'])\n",
        "\n",
        "df = class_distribution_count(data_dir_train)\n",
        "df"
      ],
      "metadata": {
        "id": "QnjZjWK_w2Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the Number of image in each class.\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x=\"No. of Image\", y=\"Class\", data=df,\n",
        "            label=\"Class\")"
      ],
      "metadata": {
        "id": "rT1I8gGew_t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   seborrheic keratosis has the least number of samples only 77.\n",
        "*   pigmented benign keratosis (462 Samples), melanoma (438 Samples), basal cell carcinoma (376 Samples), and nevus (357 Samples) classes dominates the data in terms proportionate number of samples ."
      ],
      "metadata": {
        "id": "tOvhg5QDxDd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7 - Handling class imbalances: Rectify class imbalances present in the training dataset with Augmentor library.**"
      ],
      "metadata": {
        "id": "y4U5OfZfwtl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a python package known as Augmentor (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples.\n",
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "lffvG8mJxT26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_training_dataset=\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ],
      "metadata": {
        "id": "01-ErhwxxXZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentor stored the augmented images in output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ],
      "metadata": {
        "id": "fg4KLP4dxjR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Count total number of image generated by Augmentor.\n",
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "metadata": {
        "id": "zSi7LtpwxnDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "see the distribution of augmented data after adding new images to the original training data."
      ],
      "metadata": {
        "id": "Pmi_KzTMxtKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "path_list = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "#path_list"
      ],
      "metadata": {
        "id": "3L8wJj1qxuJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "#lesion_list_new"
      ],
      "metadata": {
        "id": "C5qOPwDuxyIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_dict_new = dict(zip(path_list, lesion_list_new))"
      ],
      "metadata": {
        "id": "aWF-Dsjdx0fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataframe that store path and label of the images generated by Augmentor\n",
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])"
      ],
      "metadata": {
        "id": "7vKK14Jwx3Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label count.\n",
        "df2['Label'].value_counts()"
      ],
      "metadata": {
        "id": "SbjC6Ohtx6MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Model Building & training on the rectified class imbalance data :\n",
        "Create a CNN model, which can accurately detect 9 classes present in the dataset. While building the model, rescale images to normalize pixel values between (0,1).\n",
        "Choose an appropriate optimiser and loss function for model training\n",
        "Train the model for ~30 epochs\n",
        "Write your findings after the model fit, see if the issues are resolved or not?**"
      ],
      "metadata": {
        "id": "VcWSRW8WyD_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "h3xZz-17yIhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a training dataset\n",
        "data_dir_train=\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
        "\n",
        "#Training dataset.\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,    #20% fraction of data to reserve for validation.\n",
        "  subset = \"training\",\n",
        "  image_size=(img_height, img_width),label_mode='categorical',  #label_mode='categorical' means that the labels are encoded as a categorical vector\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "qhatx9hGyN7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a validation dataset\n",
        "#Validation dataset.\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"validation\",\n",
        "  image_size=(img_height, img_width),label_mode='categorical',   #label_mode='categorical' means that the labels are encoded as a categorical vector\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "RgkVfcjjyTDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating model\n",
        "#Model\n",
        "\n",
        "model3 = Sequential()\n",
        "\n",
        "model3.add(rescale)   #Rescaling Layer\n",
        "\n",
        "#First Convulation layer\n",
        "model3.add(layers.Conv2D(32,kernel_size=(2,2),activation='relu'))\n",
        "model3.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model3.add(layers.Dropout(0.25))\n",
        "\n",
        "#Second Convulation Layer\n",
        "model3.add(layers.Conv2D(64,kernel_size=(2,2),activation='relu'))\n",
        "model3.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model3.add(layers.Dropout(0.25))\n",
        "\n",
        "#Third Convulation Layer\n",
        "model3.add(layers.Conv2D(128,kernel_size=(2,2),activation='relu'))\n",
        "model3.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Flatten Layer\n",
        "model3.add(layers.Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "model3.add(layers.Dense(512,activation='relu'))\n",
        "\n",
        "#Dropout layer\n",
        "model3.add(layers.Dropout(0.25))\n",
        "\n",
        "#Batch normalization: is a method used to make artificial neural networks faster and more stable through normalization\n",
        "#of the layers' inputs by re-centering and re-scaling.\n",
        "model3.add(layers.BatchNormalization())\n",
        "\n",
        "#Dense Layer\n",
        "model3.add(layers.Dense(128,activation='relu'))\n",
        "\n",
        "#Dropout layer with 50% Fraction of the input units to drop.\n",
        "model3.add(layers.Dropout(0.50))\n",
        "\n",
        "#Batch normalization\n",
        "model3.add(layers.BatchNormalization())\n",
        "\n",
        "#Dense layer with Softmax activation function.\n",
        "model3.add(layers.Dense(len(class_names),activation='softmax'))"
      ],
      "metadata": {
        "id": "T6CrqfqLyY5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling Model\n",
        "model3.compile(optimizer='Adam',\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5TDM5PtSybSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training model\n",
        "epochs = 30\n",
        "history = model3.fit(train_ds,epochs=epochs,validation_data=val_ds,verbose=1)"
      ],
      "metadata": {
        "id": "ul9gVH8WyhvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing results"
      ],
      "metadata": {
        "id": "GYM3c9lsyuOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T3nRf65CywCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESULT**\n",
        "*   As per the final model (model3) Training accuracy and validation accuracy increases.\n",
        "*   Model overfitting issue is solved.\n",
        "*   Class rebalance helps in augmentation and achieving the best Training and validation accuracy."
      ],
      "metadata": {
        "id": "__T7Z0uYy2jt"
      }
    }
  ]
}